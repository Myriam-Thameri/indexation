{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.912783Z",
     "start_time": "2024-06-20T09:12:57.188Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import webtext\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import math as m\n",
    "ids = nltk.corpus.webtext.fileids()\n",
    "N = len(ids)\n",
    "ps = PorterStemmer()\n",
    "dict={}\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text_tokenize = word_tokenize(text)\n",
    "    text_tokenize = [word.lower() for word in text_tokenize]\n",
    "    word_filtered = [word for word in text_tokenize if not word in stopwords.words('english')]\n",
    "    word_lem = [lemmatizer.lemmatize(word) for word in word_filtered]\n",
    "    return text_tokenize , word_filtered , word_lem"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.918199Z",
     "start_time": "2024-06-20T09:12:59.912783Z"
    }
   },
   "id": "1f70dd716dc39821",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def Documents_preprocessing():\n",
    "    docs={}\n",
    "    all_words = []\n",
    "    for id in ids:\n",
    "        with open(nltk.corpus.webtext.abspath(id),'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "            text_tokenize , word_filtered , word_lem = text_preprocessing(text)\n",
    "            word_count = {}\n",
    "            for word in word_filtered:\n",
    "                word_count[word] = word_count.get(word,0) + 1\n",
    "            data = [text_tokenize,word_filtered,word_lem,word_count]\n",
    "            docs[id] = data\n",
    "            all_words += text_tokenize\n",
    "    return docs , all_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.924845Z",
     "start_time": "2024-06-20T09:12:59.919661Z"
    }
   },
   "id": "b42f2645b3856217",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def Indexation(all_words,docs):\n",
    "    ind= defaultdict(lambda : {})\n",
    "    for id , data in docs.items():\n",
    "        text_tokenize , word_filtered , word_lem ,word_count = data\n",
    "        for word , count in word_count.items():\n",
    "            tf = count / len(word_filtered)\n",
    "            document_frequency = sum(word in value[1]  for key , value in docs.items())\n",
    "            freq = count\n",
    "            idf = m.log(N/(document_frequency + 1))\n",
    "            poids = (1+m.log10(freq))*(m.log10(N/document_frequency))\n",
    "            tf_idf = tf*idf\n",
    "            ind[word][id] = {'tf':tf,'frequency':freq,'tf_idf':tf_idf,'idf':idf,'poids':poids}\n",
    "    return ind"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.931914Z",
     "start_time": "2024-06-20T09:12:59.926103Z"
    }
   },
   "id": "5ef93949d7759d56",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def Recherche(mot,ind,all_words):\n",
    "    documents = []\n",
    "    poids = []\n",
    "    tfidf = []\n",
    "    freq = []\n",
    "    mot_lem = lemmatizer.lemmatize(mot)\n",
    "    if mot_lem in all_words:\n",
    "        for doc_id , word_ind in ind[mot_lem].items():\n",
    "            documents.append(doc_id)\n",
    "            poids.append(word_ind['poids'])\n",
    "            tfidf.append(word_ind['tf_idf'])\n",
    "            freq.append(word_ind['frequency'])\n",
    "            \n",
    "    return documents , poids , tfidf , freq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.937466Z",
     "start_time": "2024-06-20T09:12:59.932987Z"
    }
   },
   "id": "10bc622038d37b5e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def definition(word):\n",
    "  syns = wordnet.synsets(word)\n",
    "  if (len(syns) == 0):\n",
    "    dfn =\"\"\n",
    "  else:\n",
    "    dfn = syns[0].definition()\n",
    "  return dfn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.942631Z",
     "start_time": "2024-06-20T09:12:59.938514Z"
    }
   },
   "id": "76cbf06378283099",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def synant(word):\n",
    "  synonyms = []\n",
    "  antonyms = []\n",
    "  syns = wordnet.synsets(word)\n",
    "  for syn in syns:\n",
    "    for l in syn.lemmas():\n",
    "      synonyms.append(l.name())\n",
    "      if l.antonyms():\n",
    "        antonyms.append(l.antonyms()[0].name())\n",
    "  return synonyms, antonyms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.947849Z",
     "start_time": "2024-06-20T09:12:59.942631Z"
    }
   },
   "id": "c5f36fdb1812bfc9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def fonction_grammaticale(word):\n",
    "  tokens = nltk.word_tokenize(word)\n",
    "  tags = nltk.pos_tag(tokens)\n",
    "  fg = [tag[1] for tag in tags]\n",
    "  return fg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:12:59.952179Z",
     "start_time": "2024-06-20T09:12:59.947849Z"
    }
   },
   "id": "d6341b33b3770257",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "docs , all_words = Documents_preprocessing()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T09:13:36.452436Z",
     "start_time": "2024-06-20T09:12:59.953270Z"
    }
   },
   "id": "1eb3815dd3cb9ee4",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
